---
title: "Package 'batchtools'"
date: "07.09.2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# The 'batchtools'-package and its usage in IDE+A
## What does the package do?
Let's say you have

* algorithms (a1,a2, ...,an)
* settings (s1, ...)

You want to test and compare them on some functions:

* functions (f1, ...)

The 'batchtools' package can do that in a nicely organised way and fully automatic.

You want to do it **automatically on a cluster**? Even better.

### Example

```{r echo=TRUE, results='hide', message=FALSE}
## Only for this demo, deletes all Experiments for a fresh strart in the presentation
unlink("~/someTestDir/Experiments/Seminar/", recursive = TRUE)

require(ideaBatch)
source(paste0(system.file(package = "ideaBatch"),"/sources.R"))

## Create an Experiment Registry with a Dir-Name and a Sub-Directory for each test.
reg <- ideaMakeRegistry("Seminar","Test1") 

## Add Objective Functions
addProblem("Rosen2D", of_smoofByName("Rosenbrock",2))
addProblem("Rastr2D", of_smoofByName("Rastrigin",2))
    
## Add Algorithms
addAlgorithm("optimLHD", algorithm_SpotOptimByName("optimLHD", c(-5,-5),c(5,5),
                                                  control = list(funEvals = 100)))
addAlgorithm("cmaesCMAES",algorithm_CMAES(c(-5,-5),c(5,5), control = list("maxit" = 100)))
    
## Build Experiments
addExperiments(repls = 10)
```

### Show a summary - which Experiments are run?

```{R}
summarizeExperiments()
```

### Run your experiments

```{R, message=FALSE, results='hide'}
# ideaSubmitJobs()
# ideaSubmitJobs(ids = findNotSubmitted())
# 
#ideaSubmitJobs(ids= findExperiments())
submitJobs()
```

The submitJobs command submits Experiments to the cluster. It is possible to submit all defined Experiments, only specific ones, or filter for a certain group of experiments like: notSubmitted, notFinished, notStarted, aborted etc.

### Results
Experiment results will be nicely kept. As they share the same structure every time, general postprocessing functions can be defined and reused / shared in the team.

```{R}
results <- reduceResultsList()
df <- generateResultDF(results)
g <- anyTimePerformancePlot(df[which(df$problemName == "Rastr2D"),],ylog = T, useMinMax = T)
print(g + ggtitle("Anytime Performance on Rastrigin Function"))
```

### Redo / Adapt Experiments
It's also very easy to rerun old experiments or change them:

```{R, message=FALSE, results='hide'}
submitJobs(id = findJobs()) ## Rerun all experiments, independent of their status
```

```{R, message=FALSE}
addAlgorithm("optimDE", algorithm_SpotOptimByName("optimDE", c(-5,-5),c(5,5),
                                                  control = list(funEvals = 100)))

addExperiments(repls = 20)

summarizeExperiments()
```

```{R, message=FALSE, results='hide'}
submitJobs() ## Only runs the experiments which havent already been done
```

```{R}
results <- reduceResultsList()
df <- generateResultDF(results)
g <- anyTimePerformancePlot(df[which(df$problemName == "Rastr2D"),],ylog = T, useMinMax = T)
print(g + ggtitle("Anytime Performance on Rastrigin Function"))
```

## Pros/Cons

* +Easy task submission on the cluster
* +Define Algorithms / Objective functions etc. only once, then they can be nicely shared in the same strucutre
* +Same for Postprocessing etc.

* -Initial Setup

## Automatic Installer
* Github package ideaBatch
* devtools::install_github("frehbach/ideaBatch")


